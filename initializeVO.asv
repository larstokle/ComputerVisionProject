function [pose, state] = initializeVO(img0, img1, K0, K1, H_I0)
%initializeVO: finds position of second image and makes a list of landmarks
%   
%       Input: 
%           img0:   first grayscale image of sequence
%           img1:   first greyscale keyframe image of sequence
%           K0:     intrinsic matrix for camera that took img0
%           K1:     intrinsix matrix for camera that took img1
    k = 200;
    
    %% find keypoints in img0
    corners = detectHarrisFeatures(img0); %tryout, change with homemade or soln, SIFT??
    strongestCorners = corners.selectStrongest(k);
    strongestCornersCoord = strongestCorners.Location;
    
    %validation plot
    figure(1);clf;
    subplot(2,1,1);
    imshow(img0);
    hold on;
    scatter(strongestCornersCoord(:,1), strongestCornersCoord(:,2),'x');
    scatter(621,188/2,'g');
    
    %% track keypoints from img0 in img1
    pointTracker = vision.PointTracker('BlockSize', [9,9]);
    initialize(pointTracker, strongestCornersCoord, img0);
    [trackedPoints, point_validity] = step(pointTracker, img1); % implements klt, change 
    
    %valid coords
    validStrongestCornersCoord = strongestCorners.Location(point_validity,:)';
    validTrackedPoints = trackedPoints(point_validity,:)';
    
    % validation plots
    plot([validStrongestCornersCoord(1,:); validTrackedPoints(1,:)],[validStrongestCornersCoord(2,:); validTrackedPoints(2,:)],'g','Linewidth',1);
    subplot(2,1,2);
    imshow(img1);
    hold on;
    scatter(validTrackedPoints(1,:),validTrackedPoints(2,:),'x');
    
    %% get relative camera pose
    %valid coords in 2D hom
    validStrongestCornersCoordHom = K0\[validStrongestCornersCoord; ones(1, sum(point_validity))];
    validStrongestCornersCoordHom = validStrongestCornersCoordHom./repmat(validStrongestCornersCoordHom(3,:),3,1);
    validTrackedPointsHom = K1\[validTrackedPoints; ones(1, sum(point_validity))];
    validTrackedPointsHom = validTrackedPointsHom./repmat(validTrackedPointsHom(3,:),3,1);
    
    %estimate hom trans
    E = estimateEssentialMatrix(validStrongestCornersCoordHom, validTrackedPointsHom, K0, K1);
    [R_01,u3] = decomposeEssentialMatrix(E);
    [R_01, T_01] = disambiguateRelativePose(R_01, u3, validStrongestCornersCoordHom, validTrackedPointsHom, K0, K1);
    
    
    %% homogenous transformation matrix
    H_01 = [R_01, T_01;
           0, 0, 0, 1];        % relative
    H_I1 = H_I0*H_01;          % absolute
    
    H_0I = inv(H_I0);
    H_1I = inv(H_I1);
    
    figure(2),clf;
    quiver(H_I0(1,4),H_I0(2,4),H_I0(1,1),H_I0(1,2),'Color','r');
    quiver(H_I0(1,4),H_I0(2,4),H_I0(2,1),H_I0(2,2),'Color','g');
    quiver(H_I0(1,4),H_I0(2,4),H_I0(,1),H_I0(1,2),'Color','r')
    %% get landmarks in world coord
    P_landmark_W = linearTriangulation(validStrongestCornersCoordHom, validTrackedPointsHom, H_0I(1:3,:), H_1I(1:3,:));
    
    %% return values
    pose = H_I1;
    
    %maybe something else in state
    state.landmarks = P_landmark_W;
    state.lastCorrespondencePoint = validTrackedPoints;
    state.lastCorrespondenceLandmarkIndex = (1:size(validTrackedPoints,2))';
end

